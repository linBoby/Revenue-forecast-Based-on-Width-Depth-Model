{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于Width & Depth Model的人群收入分类预测\n",
    "标签为收入分类，特征包括年龄、工作类型（公立私立）、教育程度（本科、硕士）、受教育年份、婚姻状况、家庭关系、人种、性别、每周工作时长..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、引入工具库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "# 高级文件处理模块\n",
    "import shutil\n",
    "import math\n",
    "from datetime import datetime\n",
    "# 多进程模块\n",
    "import multiprocessing\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import data\n",
    "from tensorflow.python.feature_column import feature_column\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、基本设定与数据读写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'D&W Model'\n",
    "# 训练集、测试集文件名\n",
    "TRAIN_DATA_FILES_PATTERN = 'adult_train.csv'\n",
    "TEST_DATA_FILES_PATTERN = 'adult_test.csv'\n",
    "\n",
    "# 一些开关设置    恢复训练 特征处理 扩展特征 多线程\n",
    "RESUME_TRAINING = False\n",
    "PROCESS_FEATURES = True\n",
    "EXTEND_FEATURE_COLUMNS = True\n",
    "MULTI_THREADING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('adult_train.csv',header = None)\n",
    "data.columns =['age','workclass','fnlwgt','education','education_num','marital_status',\n",
    "              'occupation','relationship','race','gender','capital_gain',\n",
    "              'capital_loss','hours_per_week','native_country','income_bracket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race  gender  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country income_bracket  \n",
       "0          2174             0              40  United-States          <=50K  \n",
       "1             0             0              13  United-States          <=50K  \n",
       "2             0             0              40  United-States          <=50K  \n",
       "3             0             0              40  United-States          <=50K  \n",
       "4             0             0              40           Cuba          <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、定义数据集的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gender': ['Male', 'Female'], 'workclass': ['State-gov', 'Self-emp-not-inc', 'Private', 'Federal-gov', 'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'], 'relationship': ['Not-in-family', 'Husband', 'Wife', 'Own-child', 'Unmarried', 'Other-relative'], 'marital_status': ['Never-married', 'Married-civ-spouse', 'Divorced', 'Married-spouse-absent', 'Separated', 'Married-AF-spouse', 'Widowed'], 'race': ['White', 'Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other'], 'education': ['Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college', 'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school', '5th-6th', '10th', '1st-4th', 'Preschool', '12th']}\n",
      "全部列名：['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'gender', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income_bracket']\n",
      "数值型的特征:['age', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
      "类别型的特征:['gender', 'workclass', 'relationship', 'marital_status', 'race', 'education', 'occupation', 'native_country']\n",
      "目标列：income_bracket-不同的分类结果：['<=50K', '>50K']\n",
      "没有用到的列:[]\n"
     ]
    }
   ],
   "source": [
    "# 数据集每个字段的名称\n",
    "HEADER = ['age','workclass','fnlwgt','education','education_num','marital_status',\n",
    "              'occupation','relationship','race','gender','capital_gain',\n",
    "              'capital_loss','hours_per_week','native_country','income_bracket']\n",
    "# 数据集默认值（数值型默认0，字符串型默认空串）\n",
    "HEADER_DEFAULTS = [[0],[''],[0],[''],[0],[''],[''],[''],\n",
    "                   [''],[''],[0],[0],[0],[''],['']]\n",
    "# I 数值型的列\n",
    "NUMERIC_FEATURE_NAMES = ['age','education_num','capital_gain','capital_loss',\n",
    "                         'hours_per_week']\n",
    "# II 类别型的列，同时把列的不同值列出来\n",
    "# print(list(data['workclass'].unique()))\n",
    "CATEGORICAL_FEATURE_NAMES_WITH_VOCABULARY = {\n",
    "    'gender':list(data['gender'].unique()),\n",
    "    'race':list(data['race'].unique()),\n",
    "    'education':list(data['education'].unique()),\n",
    "    'marital_status':list(data['marital_status'].unique()),\n",
    "    'relationship':list(data['relationship'].unique()),\n",
    "    'workclass':list(data['workclass'].unique())\n",
    "}\n",
    "print(CATEGORICAL_FEATURE_NAMES_WITH_VOCABULARY)\n",
    "\n",
    "# III 分桶列，类别比较多时使用\n",
    "CATEGORICAL_FEATURE_NAMES_WITH_BUCKET_SIZE = {\n",
    "    'occupation':50,\n",
    "    'native_country':100\n",
    "}\n",
    "\n",
    "# 类别型列名list\n",
    "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURE_NAMES_WITH_VOCABULARY.keys())+list(CATEGORICAL_FEATURE_NAMES_WITH_BUCKET_SIZE.keys())\n",
    "    \n",
    "# 总的列名list\n",
    "FEATURE_NAMES  = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "\n",
    "# 目标列名\n",
    "TARGET_NAME = 'income_bracket'\n",
    "\n",
    "# 目标不同类别的取值\n",
    "TARGET_LABELS = ['<=50K','>50K']\n",
    "\n",
    "# 权重列\n",
    "WEIGHT_COLUMN_NAME = 'fnlwgt'\n",
    "\n",
    "# 没有用到的列\n",
    "UNUSED_FEATURE_NAMES = list(set(HEADER) - set(FEATURE_NAMES) - \n",
    "                            {TARGET_NAME}-{WEIGHT_COLUMN_NAME})\n",
    "\n",
    "print('全部列名：{}'.format(HEADER))\n",
    "print('数值型的特征:{}'.format(NUMERIC_FEATURE_NAMES))\n",
    "print('类别型的特征:{}'.format(CATEGORICAL_FEATURE_NAMES))\n",
    "print('目标列：{}-不同的分类结果：{}'.format(TARGET_NAME,TARGET_LABELS))\n",
    "print('没有用到的列:{}'.format(UNUSED_FEATURE_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、做一些数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race  gender  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country income_bracket  \n",
       "0          2174             0              40  United-States          <=50K  \n",
       "1             0             0              13  United-States          <=50K  \n",
       "2             0             0              40  United-States          <=50K  \n",
       "3             0             0              40  United-States          <=50K  \n",
       "4             0             0              40           Cuba          <=50K  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(TRAIN_DATA_FILES_PATTERN,header=None,names=HEADER)\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null object\n",
      "fnlwgt            32561 non-null int64\n",
      "education         32561 non-null object\n",
      "education_num     32561 non-null int64\n",
      "marital_status    32561 non-null object\n",
      "occupation        32561 non-null object\n",
      "relationship      32561 non-null object\n",
      "race              32561 non-null object\n",
      "gender            32561 non-null object\n",
      "capital_gain      32561 non-null int64\n",
      "capital_loss      32561 non-null int64\n",
      "hours_per_week    32561 non-null int64\n",
      "native_country    32561 non-null object\n",
      "income_bracket    32561 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>3.256100e+04</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>1.897784e+05</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>1.055500e+05</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.178270e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.783560e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.370510e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
       "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
       "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours_per_week  \n",
       "count    32561.000000  \n",
       "mean        40.437456  \n",
       "std         12.347429  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_SIZE = train_data.shape[0]\n",
    "test_data = pd.read_csv(TEST_DATA_FILES_PATTERN,skiprows=1)\n",
    "TEST_DATA_SIZE = test_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算数值列的统计指标用于变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>stdv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>90</td>\n",
       "      <td>38.581647</td>\n",
       "      <td>17</td>\n",
       "      <td>13.640433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>16</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1</td>\n",
       "      <td>2.572720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_gain</th>\n",
       "      <td>99999</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>0</td>\n",
       "      <td>7385.292085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_loss</th>\n",
       "      <td>4356</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>0</td>\n",
       "      <td>402.960219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours_per_week</th>\n",
       "      <td>99</td>\n",
       "      <td>40.437456</td>\n",
       "      <td>1</td>\n",
       "      <td>12.347429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  max         mean  min         stdv\n",
       "age                90    38.581647   17    13.640433\n",
       "education_num      16    10.080679    1     2.572720\n",
       "capital_gain    99999  1077.648844    0  7385.292085\n",
       "capital_loss     4356    87.303830    0   402.960219\n",
       "hours_per_week     99    40.437456    1    12.347429"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 方便接下来做幅度缩放\n",
    "means = train_data[NUMERIC_FEATURE_NAMES].mean(axis=0)\n",
    "stdvs = train_data[NUMERIC_FEATURE_NAMES].std(axis=0)\n",
    "maxs = train_data[NUMERIC_FEATURE_NAMES].max(axis=0)\n",
    "mins = train_data[NUMERIC_FEATURE_NAMES].min(axis=0)\n",
    "df_stats = pd.DataFrame({'mean':means,'stdv':stdvs,'max':maxs,'min':mins})\n",
    "df_stats.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 存储统计分析数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_csv(path_or_buf = 'adult.stats.csv',header=True,index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5、定义数据输入函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  a、解析csv与预处理逻辑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv_row(csv_row):\n",
    "    columns = tf.decode_csv(csv_row,record_defaults=HEADER_DEFAULTS)\n",
    "    # 把tensor和对应的列名打包成字典\n",
    "    features = dict(zip(HEADER,columns))\n",
    "    # 取出无用的列\n",
    "    for colum in UNUSED_FEATURE_NAMES:\n",
    "        features.pop(column)\n",
    "    # 取出目标列\n",
    "    target = features.pop(TARGET_NAME)\n",
    "    # 返回 字典+target序列形式\n",
    "    return features,target\n",
    "\n",
    "# 处理特征 butai ok\n",
    "def process_features(features):\n",
    "    # 判断，字典中新的key capital_indicator也同样对应一个tensor\n",
    "    capital_indicator = features['capital_gain'] > features['capital_loss']\n",
    "    features['capital_indicator'] = tf.cast(capital_indicator, dtype=tf.int32)\n",
    "    # 返回feature字典\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b、数据输入函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入到estimator的数据解析函数\n",
    "def csv_input_fn(file_names,mode=tf.estimator.ModeKeys.EVAL,\n",
    "                skip_header_lines=0,\n",
    "                num_epochs=None,\n",
    "                batch_size=200):\n",
    "    # 训练阶段用shuffle\n",
    "    shuffle = True if mode == tf.estimator.ModeKeys.TRAIN else False\n",
    "    # 多线程\n",
    "    num_threads = multiprocessing.cpu_count() if MULTI_THREADING else 1\n",
    "    # 输出信息\n",
    "    print('\\n')\n",
    "    print('数据输入函数input_fn:')\n",
    "    print('====================')\n",
    "    print('输入文件：{}'.format(file_names))\n",
    "    print('一批大小：{}'.format(batch_size))\n",
    "    print('迭代的轮次：{}'.format(num_epochs))\n",
    "    print('模式：{}'.format(mode))\n",
    "    print('Thread Count:{}'.format(num_threads))\n",
    "    print('Shuffle:{}'.format(shuffle))\n",
    "    print('===================')\n",
    "    \n",
    "    dataset = tf.data.TextLineDataset(filenames=file_names)\n",
    "    dataset = dataset.skip(skip_header_lines)\n",
    "    # 乱序\n",
    "    if shuffle:\n",
    "        dataset  = dataset.shuffle(buffer_size = 2 * batch_size + 1)\n",
    "    # 取一个batch    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    # 对数据进行解析\n",
    "    dataset = dataset.map(lambda csv_row:parse_csv_row(csv_row),num_parallel_calls = num_threads)\n",
    "    print('/n',dataset)\n",
    "    # 如果需要多处理\n",
    "    if PROCESS_FEATURES:\n",
    "        dataset  = dataset.map(lambda features,target:(process_features(features),\n",
    "                                            target),num_parallel_calls = num_threads)\n",
    "    # 每个轮次完成后，重启dataset\n",
    "    dataset  = dataset.repeat(num_epochs)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    # 取出满足 特征字典+ 结果标签的值\n",
    "    features,target = iterator.get_next()\n",
    "    return features,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "数据输入函数input_fn:\n",
      "====================\n",
      "输入文件：['adult_train.csv']\n",
      "一批大小：200\n",
      "迭代的轮次：None\n",
      "模式：eval\n",
      "Thread Count:4\n",
      "Shuffle:False\n",
      "===================\n",
      "/n <ParallelMapDataset shapes: ({relationship: (?,), gender: (?,), marital_status: (?,), native_country: (?,), education_num: (?,), education: (?,), fnlwgt: (?,), workclass: (?,), capital_loss: (?,), occupation: (?,), hours_per_week: (?,), capital_gain: (?,), race: (?,), age: (?,)}, (?,)), types: ({relationship: tf.string, gender: tf.string, marital_status: tf.string, native_country: tf.string, education_num: tf.int32, education: tf.string, fnlwgt: tf.int32, workclass: tf.string, capital_loss: tf.int32, occupation: tf.string, hours_per_week: tf.int32, capital_gain: tf.int32, race: tf.string, age: tf.int32}, tf.string)>\n",
      "csv文件的特征：['relationship', 'gender', 'marital_status', 'capital_loss', 'native_country', 'education_num', 'education', 'fnlwgt', 'workclass', 'capital_indicator', 'occupation', 'hours_per_week', 'capital_gain', 'race', 'age']\n",
      "csv文件的标签：Tensor(\"IteratorGetNext:15\", shape=(?,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "features,target = csv_input_fn(file_names = ['adult_train.csv'])\n",
    "print('csv文件的特征：{}'.format(list(features.keys())))\n",
    "print('csv文件的标签：{}'.format(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6、定义特征列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a、对数值型变量做福都缩放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>stdv</th>\n",
       "      <th>feature_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>90</td>\n",
       "      <td>38.581647</td>\n",
       "      <td>17</td>\n",
       "      <td>13.640433</td>\n",
       "      <td>age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>16</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>education_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_gain</th>\n",
       "      <td>99999</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>0</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>capital_gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_loss</th>\n",
       "      <td>4356</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>0</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>capital_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours_per_week</th>\n",
       "      <td>99</td>\n",
       "      <td>40.437456</td>\n",
       "      <td>1</td>\n",
       "      <td>12.347429</td>\n",
       "      <td>hours_per_week</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  max         mean  min         stdv    feature_name\n",
       "age                90    38.581647   17    13.640433             age\n",
       "education_num      16    10.080679    1     2.572720   education_num\n",
       "capital_gain    99999  1077.648844    0  7385.292085    capital_gain\n",
       "capital_loss     4356    87.303830    0   402.960219    capital_loss\n",
       "hours_per_week     99    40.437456    1    12.347429  hours_per_week"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats = pd.read_csv('adult.stats.csv',header=0,index_col=0)\n",
    "# df_stats.head(10)\n",
    "df_stats['feature_name'] = NUMERIC_FEATURE_NAMES\n",
    "df_stats.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b、构建不同的特征列（特征工程）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns:{'native_country_x_occupation_embedded': _EmbeddingColumn(categorical_column=_CrossedColumn(keys=('native_country', 'occupation'), hash_bucket_size=10000, hash_key=None), dimension=3, combiner='mean', layer_creator=<function embedding_column.<locals>._creator at 0x7f56d108abf8>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True), 'marital_status': _VocabularyListCategoricalColumn(key='marital_status', vocabulary_list=('Never-married', 'Married-civ-spouse', 'Divorced', 'Married-spouse-absent', 'Separated', 'Married-AF-spouse', 'Widowed'), dtype=tf.string, default_value=-1, num_oov_buckets=0), 'education_num': _NumericColumn(key='education_num', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x7f56d108a9d8>), 'hours_per_week': _NumericColumn(key='hours_per_week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x7f56d108ac80>), 'education_x_occupation': _CrossedColumn(keys=('education', 'occupation'), hash_bucket_size=10000, hash_key=None), 'age_buckets': _BucketizedColumn(source_column=_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x7f56d108a8c8>), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), 'capital_loss': _NumericColumn(key='capital_loss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x7f56d108aa60>), 'occupation': _HashedCategoricalColumn(key='occupation', hash_bucket_size=50, dtype=tf.string), 'relationship': _VocabularyListCategoricalColumn(key='relationship', vocabulary_list=('Not-in-family', 'Husband', 'Wife', 'Own-child', 'Unmarried', 'Other-relative'), dtype=tf.string, default_value=-1, num_oov_buckets=0), 'age': _NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x7f56d108a8c8>), 'gender': _VocabularyListCategoricalColumn(key='gender', vocabulary_list=('Male', 'Female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), 'native_country_embedded': _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='native_country', hash_bucket_size=100, dtype=tf.string), dimension=3, combiner='mean', layer_creator=<function embedding_column.<locals>._creator at 0x7f56d108a400>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True), 'native_country': _HashedCategoricalColumn(key='native_country', hash_bucket_size=100, dtype=tf.string), 'native_country_x_occupation': _CrossedColumn(keys=('native_country', 'occupation'), hash_bucket_size=10000, hash_key=None), 'education': _VocabularyListCategoricalColumn(key='education', vocabulary_list=('Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college', 'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school', '5th-6th', '10th', '1st-4th', 'Preschool', '12th'), dtype=tf.string, default_value=-1, num_oov_buckets=0), 'occupation_embedded': _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='occupation', hash_bucket_size=50, dtype=tf.string), dimension=3, combiner='mean', layer_creator=<function embedding_column.<locals>._creator at 0x7f56d108a950>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True), 'age_buckets_x_race': _CrossedColumn(keys=(_BucketizedColumn(source_column=_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x7f56d108a8c8>), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), _VocabularyListCategoricalColumn(key='race', vocabulary_list=('White', 'Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), hash_bucket_size=10000, hash_key=None), 'workclass': _VocabularyListCategoricalColumn(key='workclass', vocabulary_list=('State-gov', 'Self-emp-not-inc', 'Private', 'Federal-gov', 'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'), dtype=tf.string, default_value=-1, num_oov_buckets=0), 'capital_indicator': _IdentityCategoricalColumn(key='capital_indicator', num_buckets=2, default_value=0), 'education_x_occupatio_embedded': _EmbeddingColumn(categorical_column=_CrossedColumn(keys=('education', 'occupation'), hash_bucket_size=10000, hash_key=None), dimension=3, combiner='mean', layer_creator=<function embedding_column.<locals>._creator at 0x7f56d108aae8>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True), 'capital_gain': _NumericColumn(key='capital_gain', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x7f56d1333b70>), 'race': _VocabularyListCategoricalColumn(key='race', vocabulary_list=('White', 'Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other'), dtype=tf.string, default_value=-1, num_oov_buckets=0)}\n"
     ]
    }
   ],
   "source": [
    "# 使用tf构建 高级特征\n",
    "def extend_feature_columns(feature_columns,hparams):\n",
    "    # 分桶：年龄\n",
    "    age_buckets = tf.feature_column.bucketized_column(\n",
    "        feature_columns['age'],boundaries=[18,25,30,35,40,45,50,55,60,65])\n",
    "    # 特征交叉组合并hash分桶1:教育与职业\n",
    "    education_x_occupation  = tf.feature_column.crossed_column(\n",
    "        ['education','occupation'],hash_bucket_size = int(1e4))\n",
    "    # 特征交叉组合并hash分桶：年龄与种族\n",
    "    age_buckets_x_race  =  tf.feature_column.crossed_column(\n",
    "        [age_buckets,feature_columns['race']],hash_bucket_size= int(1e4))\n",
    "    # 特征交叉组合并hash分桶：国家与职业\n",
    "    native_country_x_occupation = tf.feature_column.crossed_column(\n",
    "        ['native_country','occupation'],hash_bucket_size = int(1e4))\n",
    "    # 对类别类型做embedding:国家\n",
    "    native_country_embedded = tf.feature_column.embedding_column(\n",
    "        feature_columns['native_country'],dimension = hparams['embedding_size']\n",
    "    )\n",
    "    # 对类别类型做embedding:职业\n",
    "    occupation_embedded = tf.feature_column.embedding_column(\n",
    "        feature_columns['occupation'],dimension = hparams['embedding_size']\n",
    "    )\n",
    "    # 对交叉组合并分桶过后的进行embedding\n",
    "    education_x_occupation_embedded = tf.feature_column.embedding_column(\n",
    "        education_x_occupation,dimension=hparams['embedding_size']\n",
    "    )\n",
    "    native_country_x_occupation_embedded  = tf.feature_column.embedding_column(\n",
    "        native_country_x_occupation,dimension = hparams['embedding_size']\n",
    "    )\n",
    "    # 构建feature columns\n",
    "    feature_columns['age_buckets'] = age_buckets\n",
    "    feature_columns['education_x_occupation']= education_x_occupation\n",
    "    feature_columns['age_buckets_x_race'] = age_buckets_x_race\n",
    "    feature_columns['native_country_x_occupation'] = native_country_x_occupation\n",
    "    feature_columns['native_country_embedded'] = native_country_embedded\n",
    "    feature_columns['occupation_embedded'] = occupation_embedded\n",
    "    feature_columns['education_x_occupatio_embedded'] = education_x_occupation_embedded\n",
    "    feature_columns['native_country_x_occupation_embedded'] = native_country_x_occupation_embedded\n",
    "    #返回 feature_column字典\n",
    "    return feature_columns\n",
    "# 标准化\n",
    "def standard_scaler(x,mean,stdv):\n",
    "    return (x-mean)/(stdv)\n",
    "# 最大最小值幅度缩放\n",
    "def maxmin_scaler(x,max_value,min_value):\n",
    "    return (x-min_value)/(max_value-min_value)\n",
    "# 全部特征\n",
    "def get_feature_columns(hparams):\n",
    "    # 数值型的列\n",
    "    numeric_columns = {}\n",
    "    # 对数值型的列做幅度缩放（scaling）\n",
    "    for feature_name in NUMERIC_FEATURE_NAMES:\n",
    "        feature_mean = df_stats[df_stats.feature_name == feature_name]['mean'].values[0]\n",
    "        feature_stdv = df_stats[df_stats.feature_name == feature_name]['stdv'].values[0]\n",
    "        normalizer_fn = lambda x:standard_scaler(x,feature_mean,feature_stdv)\n",
    "        numeric_columns[feature_name] = tf.feature_column.numeric_column(feature_name,\n",
    "                                                        normalizer_fn = normalizer_fn)\n",
    "    # 新构建列（这里没有）\n",
    "    CONSTRUCTED_NUMERIC_FEATURES_NAMES = []\n",
    "    \n",
    "    if PROCESS_FEATURES:\n",
    "        for feature_name in CONSTRUCTED_NUMERIC_FEATURES_NAMES:\n",
    "            numeric_columns[feature_name] = tf.feature_column.numeric_column(feature_name)\n",
    "        \n",
    "    \n",
    "    # 对类别型的列做独热向量编码 k、v\n",
    "    categorical_column_with_vocabulary =\\\n",
    "    { item[0]:tf.feature_column.categorical_column_with_vocabulary_list(item[0],item[1])\n",
    "      for item in CATEGORICAL_FEATURE_NAMES_WITH_VOCABULARY.items()     \n",
    "    }\n",
    "    # indicator列 multi-hot编码\n",
    "    CONSTRUCTED_INDICATOR_FEATURES_NAMES = ['capital_indicator']\n",
    "    \n",
    "    categorical_column_with_identity = {}\n",
    "    \n",
    "    for feature_name in CONSTRUCTED_INDICATOR_FEATURES_NAMES:\n",
    "        categorical_column_with_identity[feature_name] = tf.feature_column.categorical_column_with_identity(\n",
    "        feature_name,num_buckets=2,default_value=0)\n",
    "    # 类别性进行hash分桶映射\n",
    "    categorical_column_with_hash_bucket = \\\n",
    "        {item[0]:tf.feature_column.categorical_column_with_hash_bucket(item[0],item[1],\n",
    "                    dtype=tf.string)for item in CATEGORICAL_FEATURE_NAMES_WITH_BUCKET_SIZE.items()\n",
    "        }\n",
    "    feature_columns= {}\n",
    "    # 更新数值列\n",
    "    if numeric_columns is not None:\n",
    "        feature_columns.update(numeric_columns)\n",
    "    \n",
    "    # 更新独热向量编码列\n",
    "    if categorical_column_with_vocabulary is not None:\n",
    "        feature_columns.update(categorical_column_with_vocabulary)\n",
    "    \n",
    "    # 更新label encoder列\n",
    "    if categorical_column_with_identity is not None:\n",
    "        feature_columns.update(categorical_column_with_identity)\n",
    "    \n",
    "    # 更新类别性hash分桶列\n",
    "    if categorical_column_with_hash_bucket is not None:\n",
    "        feature_columns.update(categorical_column_with_hash_bucket)\n",
    "    \n",
    "    # 扩充tf产出的高级列\n",
    "    if EXTEND_FEATURE_COLUMNS:\n",
    "        feature_columns = extend_feature_columns(feature_columns,hparams)\n",
    "    # 返回feature columns\n",
    "    return feature_columns\n",
    "\n",
    "feature_columns = get_feature_columns(hparams={\"num_buckets\":5,\"embedding_size\":3})\n",
    "print('Feature Columns:{}'.format(feature_columns))        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7、定义一个DNN Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a、获取宽度和深度的特征列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型当中需要的宽度和深度特征\n",
    "def get_wide_deep_columns():\n",
    "    # 取出所有列名\n",
    "    feature_columns = list(get_feature_columns(hparams).values())\n",
    "    # 过滤出深度部分的特征\n",
    "    dense_columns = list(\n",
    "        filter(lambda column:isinstance(column,feature_column._NumericColumn)\n",
    "              | isinstance(column,feature_column._EmbeddingColumn),\n",
    "               feature_columns\n",
    "              )\n",
    "    )\n",
    "    # 过滤类别型的特征\n",
    "    categorical_columns = list(\n",
    "        filter(lambda column:isinstance(column,feature_column._VocabularyListCategoricalColumn)\n",
    "              | isinstance(column,feature_column._IdentityCategoricalColumn)\n",
    "              | isinstance(column,feature_column._BucketizedColumn),\n",
    "               feature_columns\n",
    "              )\n",
    "    )\n",
    "    # 稀疏特征（wide）\n",
    "    sparse_columns = list(\n",
    "        filter(lambda column:isinstance(column,feature_column._HashedCategoricalColumn)\n",
    "              | isinstance(column,feature_column._CrossedColumn),\n",
    "               feature_columns\n",
    "              )\n",
    "    )\n",
    "    # 指示器特征\n",
    "    indicator_columns = list(\n",
    "        map(lambda column: tf.feature_column.indicator_column(column),\n",
    "            categorical_columns)\n",
    "    )\n",
    "    # 明确deep和wide部分需要的特征列\n",
    "    deep_feature_columns = dense_columns + indicator_columns\n",
    "    wide_feature_columns = categorical_columns + sparse_columns\n",
    "    \n",
    "    # 返回deep和wide部分的特征列\n",
    "    return wide_feature_columns,deep_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b、定义estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DNNComb_estimator(run_config,hparams,print_desc=False):\n",
    "    # 取得返回的特征列\n",
    "    wide_feature_columns,deep_feature_columns = get_wide_deep_columns()\n",
    "    \n",
    "    # 构建宽度深度模型\n",
    "    estimator = tf.estimator.DNNLinearCombinedClassifier(\n",
    "        # 指定分类类别的个数\n",
    "        n_classes = len(TARGET_LABELS),\n",
    "        # 如果类别不是0 dao n-1 的n个连续的整数，则需要指定一下一个list\n",
    "        label_vocabulary = TARGET_LABELS,\n",
    "        \n",
    "        # 定义宽度和深度列\n",
    "        dnn_feature_columns = deep_feature_columns,\n",
    "        linear_feature_columns = wide_feature_columns,\n",
    "        # 定义样本权重列\n",
    "        weight_column = WEIGHT_COLUMN_NAME,\n",
    "        # 关于DNN隐层的一些设定\n",
    "        dnn_hidden_units = hparams[\"hidden_units\"],\n",
    "        # 优化器选择\n",
    "        dnn_optimizer = tf.train.AdamOptimizer(),\n",
    "        # 激活函数的选择\n",
    "        dnn_activation_fn = tf.nn.relu,\n",
    "        # 配置\n",
    "        config = run_config\n",
    "    )\n",
    "    \n",
    "    if print_desc:\n",
    "        print(\"\")\n",
    "        print(\"预估器类型：\")\n",
    "        print(\"================\")\n",
    "        print(type(estimator))\n",
    "        print(\"\")\n",
    "        print(\"深度部分的列名：\")\n",
    "        print(\"================\")\n",
    "        print(deep_feature_columns)\n",
    "        print(\"\")\n",
    "        print(\"宽度部分的列名：\")\n",
    "        print(\"================\")\n",
    "        print(wide_feature_columns)\n",
    "        print(\"\")\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8、训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a、设定参数与运行参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_epochs': 100, 'hidden_units': [64, 32, 16], 'max_steps': 6512.2, 'batch_size': 500, 'embedding_size': 4}\n",
      "模型目录： D&W Model\n",
      "\n",
      "数据集大小： 32561\n",
      "Batch大小： 500\n",
      "每个轮次迭代的次数 65.122\n",
      "总迭代次数： 6512.2\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = TRAIN_DATA_SIZE\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 500\n",
    "EVAL_AFTER_SEC = 60\n",
    "TOTAL_STEPS =  (TRAIN_SIZE/BATCH_SIZE)*NUM_EPOCHS\n",
    "\n",
    "hparams = {\n",
    "    'num_epochs':NUM_EPOCHS,\n",
    "    'batch_size':BATCH_SIZE,\n",
    "    'embedding_size':4,\n",
    "    'hidden_units':[64,32,16],\n",
    "    'max_steps' : TOTAL_STEPS\n",
    "}\n",
    "model_dir = '{}'.format(MODEL_NAME)\n",
    "\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    log_step_count_steps = 5000,\n",
    "    tf_random_seed = 201805,\n",
    "    model_dir = model_dir\n",
    ")\n",
    "\n",
    "print(hparams)\n",
    "print('模型目录：',run_config.model_dir)\n",
    "print('')\n",
    "print('数据集大小：',TRAIN_SIZE)\n",
    "print('Batch大小：',BATCH_SIZE)\n",
    "print('每个轮次迭代的次数',TRAIN_SIZE/BATCH_SIZE)\n",
    "print(\"总迭代次数：\",TOTAL_STEPS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  b、定义train_and_eval 需要的配置TrainSpec和Evalue Spec 规范"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn = lambda:csv_input_fn(\n",
    "        TRAIN_DATA_FILES_PATTERN,\n",
    "        mode = tf.estimator.ModeKeys.TRAIN,\n",
    "        num_epochs = hparams['num_epochs'],\n",
    "        batch_size = hparams['batch_size']\n",
    "    ),\n",
    "    # 最大迭代次数\n",
    "    max_steps = hparams['max_steps'],\n",
    "    # 其他功能，暂无\n",
    "    hooks = None\n",
    ")\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn = lambda:csv_input_fn(\n",
    "            TRAIN_DATA_FILES_PATTERN,\n",
    "            mode = tf.estimator.ModeKeys.EVAL,\n",
    "            num_epochs = 1,\n",
    "            batch_size = hparams['batch_size'],\n",
    "        ),\n",
    "        throttle_secs = EVAL_AFTER_SEC,\n",
    "        steps = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c、通过train_and_evaluate跑实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "终止之前的训练以及结果...清除文件\n",
      "训练与验证开始于10:19:41\n",
      "........\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_service': None, '_master': '', '_protocol': None, '_model_dir': 'D&W Model', '_device_fn': None, '_evaluation_master': '', '_task_id': 0, '_global_id_in_cluster': 0, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_log_step_count_steps': 5000, '_save_summary_steps': 100, '_experimental_distribute': None, '_train_distribute': None, '_num_worker_replicas': 1, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_eval_distribute': None, '_tf_random_seed': 201805, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f566da02748>}\n",
      "\n",
      "预估器类型：\n",
      "================\n",
      "<class 'tensorflow.python.estimator.canned.dnn_linear_combined.DNNLinearCombinedClassifier'>\n",
      "\n",
      "深度部分的列名：\n",
      "================\n",
      "[_EmbeddingColumn(categorical_column=_CrossedColumn(keys=('native_country', 'occupation'), hash_bucket_size=10000, hash_key=None), dimension=4, combiner='mean', layer_creator=<function embedding_column.<locals>._creator at 0x7f56d108a158>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True), _NumericColumn(key='education_num', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x7f56d108af28>), _NumericColumn(key='hours_per_week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x7f56d108ad08>), _NumericColumn(key='capital_loss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x7f56d108ae18>), _NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x7f56d108ad90>), _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='native_country', hash_bucket_size=100, dtype=tf.string), dimension=4, combiner='mean', layer_creator=<function embedding_column.<locals>._creator at 0x7f56d108ab70>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True), _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='occupation', hash_bucket_size=50, dtype=tf.string), dimension=4, combiner='mean', layer_creator=<function embedding_column.<locals>._creator at 0x7f56d108a268>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True), _EmbeddingColumn(categorical_column=_CrossedColumn(keys=('education', 'occupation'), hash_bucket_size=10000, hash_key=None), dimension=4, combiner='mean', layer_creator=<function embedding_column.<locals>._creator at 0x7f56d108a0d0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True), _NumericColumn(key='capital_gain', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x7f56d108aea0>), _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='marital_status', vocabulary_list=('Never-married', 'Married-civ-spouse', 'Divorced', 'Married-spouse-absent', 'Separated', 'Married-AF-spouse', 'Widowed'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), _IndicatorColumn(categorical_column=_BucketizedColumn(source_column=_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x7f56d108ad90>), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65))), _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='relationship', vocabulary_list=('Not-in-family', 'Husband', 'Wife', 'Own-child', 'Unmarried', 'Other-relative'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='gender', vocabulary_list=('Male', 'Female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='education', vocabulary_list=('Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college', 'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school', '5th-6th', '10th', '1st-4th', 'Preschool', '12th'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='workclass', vocabulary_list=('State-gov', 'Self-emp-not-inc', 'Private', 'Federal-gov', 'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), _IndicatorColumn(categorical_column=_IdentityCategoricalColumn(key='capital_indicator', num_buckets=2, default_value=0)), _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='race', vocabulary_list=('White', 'Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]\n",
      "\n",
      "宽度部分的列名：\n",
      "================\n",
      "[_VocabularyListCategoricalColumn(key='marital_status', vocabulary_list=('Never-married', 'Married-civ-spouse', 'Divorced', 'Married-spouse-absent', 'Separated', 'Married-AF-spouse', 'Widowed'), dtype=tf.string, default_value=-1, num_oov_buckets=0), _BucketizedColumn(source_column=_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x7f56d108ad90>), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), _VocabularyListCategoricalColumn(key='relationship', vocabulary_list=('Not-in-family', 'Husband', 'Wife', 'Own-child', 'Unmarried', 'Other-relative'), dtype=tf.string, default_value=-1, num_oov_buckets=0), _VocabularyListCategoricalColumn(key='gender', vocabulary_list=('Male', 'Female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), _VocabularyListCategoricalColumn(key='education', vocabulary_list=('Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college', 'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school', '5th-6th', '10th', '1st-4th', 'Preschool', '12th'), dtype=tf.string, default_value=-1, num_oov_buckets=0), _VocabularyListCategoricalColumn(key='workclass', vocabulary_list=('State-gov', 'Self-emp-not-inc', 'Private', 'Federal-gov', 'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'), dtype=tf.string, default_value=-1, num_oov_buckets=0), _IdentityCategoricalColumn(key='capital_indicator', num_buckets=2, default_value=0), _VocabularyListCategoricalColumn(key='race', vocabulary_list=('White', 'Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other'), dtype=tf.string, default_value=-1, num_oov_buckets=0), _CrossedColumn(keys=('education', 'occupation'), hash_bucket_size=10000, hash_key=None), _HashedCategoricalColumn(key='occupation', hash_bucket_size=50, dtype=tf.string), _HashedCategoricalColumn(key='native_country', hash_bucket_size=100, dtype=tf.string), _CrossedColumn(keys=('native_country', 'occupation'), hash_bucket_size=10000, hash_key=None), _CrossedColumn(keys=(_BucketizedColumn(source_column=_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=<function get_feature_columns.<locals>.<lambda> at 0x7f56d108ad90>), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), _VocabularyListCategoricalColumn(key='race', vocabulary_list=('White', 'Black', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), hash_bucket_size=10000, hash_key=None)]\n",
      "\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "\n",
      "\n",
      "数据输入函数input_fn:\n",
      "====================\n",
      "输入文件：adult_train.csv\n",
      "一批大小：500\n",
      "迭代的轮次：100\n",
      "模式：train\n",
      "Thread Count:4\n",
      "Shuffle:True\n",
      "===================\n",
      "/n <ParallelMapDataset shapes: ({relationship: (?,), gender: (?,), marital_status: (?,), native_country: (?,), education_num: (?,), education: (?,), fnlwgt: (?,), workclass: (?,), capital_loss: (?,), occupation: (?,), hours_per_week: (?,), capital_gain: (?,), race: (?,), age: (?,)}, (?,)), types: ({relationship: tf.string, gender: tf.string, marital_status: tf.string, native_country: tf.string, education_num: tf.int32, education: tf.string, fnlwgt: tf.int32, workclass: tf.string, capital_loss: tf.int32, occupation: tf.string, hours_per_week: tf.int32, capital_gain: tf.int32, race: tf.string, age: tf.int32}, tf.string)>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into D&W Model/model.ckpt.\n",
      "INFO:tensorflow:loss = 126933144.0, step = 0\n",
      "INFO:tensorflow:global_step/sec: 35.3353\n",
      "INFO:tensorflow:loss = 26500464.0, step = 5000 (141.503 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6513 into D&W Model/model.ckpt.\n",
      "\n",
      "\n",
      "数据输入函数input_fn:\n",
      "====================\n",
      "输入文件：adult_train.csv\n",
      "一批大小：500\n",
      "迭代的轮次：1\n",
      "模式：eval\n",
      "Thread Count:4\n",
      "Shuffle:False\n",
      "===================\n",
      "/n <ParallelMapDataset shapes: ({relationship: (?,), gender: (?,), marital_status: (?,), native_country: (?,), education_num: (?,), education: (?,), fnlwgt: (?,), workclass: (?,), capital_loss: (?,), occupation: (?,), hours_per_week: (?,), capital_gain: (?,), race: (?,), age: (?,)}, (?,)), types: ({relationship: tf.string, gender: tf.string, marital_status: tf.string, native_country: tf.string, education_num: tf.int32, education: tf.string, fnlwgt: tf.int32, workclass: tf.string, capital_loss: tf.int32, occupation: tf.string, hours_per_week: tf.int32, capital_gain: tf.int32, race: tf.string, age: tf.int32}, tf.string)>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-09-05-10:22:56\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from D&W Model/model.ckpt-6513\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-09-05-10:23:00\n",
      "INFO:tensorflow:Saving dict for global step 6513: accuracy = 0.8925479, accuracy_baseline = 0.7614407, auc = 0.9530137, auc_precision_recall = 0.86331546, average_loss = 0.2339762, global_step = 6513, label/mean = 0.2385593, loss = 21906464.0, precision = 0.7951153, prediction/mean = 0.23623322, recall = 0.74035305\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6513: D&W Model/model.ckpt-6513\n",
      "INFO:tensorflow:Loss for final step: 18858048.0.\n",
      "..........................\n",
      "训练与验证结束于10:23:00\n",
      "\n",
      "训练和验证实验耗时198.817731秒\n"
     ]
    }
   ],
   "source": [
    "if not RESUME_TRAINING:\n",
    "    print('终止之前的训练以及结果...清除文件')\n",
    "    shutil.rmtree(model_dir,ignore_errors=True)\n",
    "else :\n",
    "    print('回复，重新加载上次训练，继续进行...')\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "time_start = datetime.now()\n",
    "print('训练与验证开始于{}'.format(time_start.strftime(\"%H:%M:%S\")))\n",
    "print('........')\n",
    "\n",
    "estimator = create_DNNComb_estimator(run_config,hparams,True)\n",
    "\n",
    "tf.estimator.train_and_evaluate(\n",
    "    estimator = estimator,\n",
    "    train_spec = train_spec,\n",
    "    eval_spec = eval_spec\n",
    ")\n",
    "\n",
    "time_end = datetime.now()\n",
    "\n",
    "print(\"..........................\")\n",
    "print('训练与验证结束于{}'.format(time_end.strftime('%H:%M:%S')))\n",
    "print('')\n",
    "time_elapsed = time_end - time_start\n",
    "print('训练和验证实验耗时{}秒'.format(time_elapsed.total_seconds()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9、评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_service': None, '_master': '', '_protocol': None, '_model_dir': 'D&W Model', '_device_fn': None, '_evaluation_master': '', '_task_id': 0, '_global_id_in_cluster': 0, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_log_step_count_steps': 5000, '_save_summary_steps': 100, '_experimental_distribute': None, '_train_distribute': None, '_num_worker_replicas': 1, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_eval_distribute': None, '_tf_random_seed': 201805, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f56c83976a0>}\n",
      "\n",
      "\n",
      "数据输入函数input_fn:\n",
      "====================\n",
      "输入文件：adult_train.csv\n",
      "一批大小：32561\n",
      "迭代的轮次：None\n",
      "模式：eval\n",
      "Thread Count:4\n",
      "Shuffle:False\n",
      "===================\n",
      "/n <ParallelMapDataset shapes: ({relationship: (?,), gender: (?,), marital_status: (?,), native_country: (?,), education_num: (?,), education: (?,), fnlwgt: (?,), workclass: (?,), capital_loss: (?,), occupation: (?,), hours_per_week: (?,), capital_gain: (?,), race: (?,), age: (?,)}, (?,)), types: ({relationship: tf.string, gender: tf.string, marital_status: tf.string, native_country: tf.string, education_num: tf.int32, education: tf.string, fnlwgt: tf.int32, workclass: tf.string, capital_loss: tf.int32, occupation: tf.string, hours_per_week: tf.int32, capital_gain: tf.int32, race: tf.string, age: tf.int32}, tf.string)>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-09-05-10:38:09\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from D&W Model/model.ckpt-6513\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-09-05-10:38:11\n",
      "INFO:tensorflow:Saving dict for global step 6513: accuracy = 0.89254797, accuracy_baseline = 0.76144063, auc = 0.9530139, auc_precision_recall = 0.86331546, average_loss = 0.23397623, global_step = 6513, label/mean = 0.23855935, loss = 1445826400.0, precision = 0.7951153, prediction/mean = 0.23623334, recall = 0.74035305\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6513: D&W Model/model.ckpt-6513\n",
      "\n",
      "\n",
      "#################################\n",
      "#训练结果指标：{'average_loss': 0.23397623, 'auc_precision_recall': 0.86331546, 'loss': 1445826400.0, 'recall': 0.74035305, 'accuracy_baseline': 0.76144063, 'accuracy': 0.89254797, 'prediction/mean': 0.23623334, 'global_step': 6513, 'label/mean': 0.23855935, 'precision': 0.7951153, 'auc': 0.9530139}\n",
      "######################################\n",
      "\n",
      "\n",
      "数据输入函数input_fn:\n",
      "====================\n",
      "输入文件：adult_test.csv\n",
      "一批大小：16279\n",
      "迭代的轮次：None\n",
      "模式：eval\n",
      "Thread Count:4\n",
      "Shuffle:False\n",
      "===================\n",
      "/n <ParallelMapDataset shapes: ({relationship: (?,), gender: (?,), marital_status: (?,), native_country: (?,), education_num: (?,), education: (?,), fnlwgt: (?,), workclass: (?,), capital_loss: (?,), occupation: (?,), hours_per_week: (?,), capital_gain: (?,), race: (?,), age: (?,)}, (?,)), types: ({relationship: tf.string, gender: tf.string, marital_status: tf.string, native_country: tf.string, education_num: tf.int32, education: tf.string, fnlwgt: tf.int32, workclass: tf.string, capital_loss: tf.int32, occupation: tf.string, hours_per_week: tf.int32, capital_gain: tf.int32, race: tf.string, age: tf.int32}, tf.string)>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-09-05-10:38:14\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from D&W Model/model.ckpt-6513\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-09-05-10:38:16\n",
      "INFO:tensorflow:Saving dict for global step 6513: accuracy = 0.8503011, accuracy_baseline = 0.7638323, auc = 0.89935285, auc_precision_recall = 0.7520994, average_loss = 0.35240632, global_step = 6513, label/mean = 0.23616774, loss = 1086798600.0, precision = 0.7015977, prediction/mean = 0.23193118, recall = 0.6371054\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6513: D&W Model/model.ckpt-6513\n",
      "\n",
      "####################################\n",
      "\n",
      "\n",
      "数据输入函数input_fn:\n",
      "====================\n",
      "输入文件：adult_test.csv\n",
      "一批大小：16279\n",
      "迭代的轮次：None\n",
      "模式：eval\n",
      "Thread Count:4\n",
      "Shuffle:False\n",
      "===================\n",
      "/n <ParallelMapDataset shapes: ({relationship: (?,), gender: (?,), marital_status: (?,), native_country: (?,), education_num: (?,), education: (?,), fnlwgt: (?,), workclass: (?,), capital_loss: (?,), occupation: (?,), hours_per_week: (?,), capital_gain: (?,), race: (?,), age: (?,)}, (?,)), types: ({relationship: tf.string, gender: tf.string, marital_status: tf.string, native_country: tf.string, education_num: tf.int32, education: tf.string, fnlwgt: tf.int32, workclass: tf.string, capital_loss: tf.int32, occupation: tf.string, hours_per_week: tf.int32, capital_gain: tf.int32, race: tf.string, age: tf.int32}, tf.string)>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-09-05-10:38:19\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from D&W Model/model.ckpt-6513\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-09-05-10:38:21\n",
      "INFO:tensorflow:Saving dict for global step 6513: accuracy = 0.8503011, accuracy_baseline = 0.7638323, auc = 0.89935285, auc_precision_recall = 0.7520994, average_loss = 0.35240632, global_step = 6513, label/mean = 0.23616774, loss = 1086798600.0, precision = 0.7015977, prediction/mean = 0.23193118, recall = 0.6371054\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6513: D&W Model/model.ckpt-6513\n",
      "\n",
      "##########################################\n",
      "#测试结果指标：{'average_loss': 0.35240632, 'auc_precision_recall': 0.7520994, 'loss': 1086798600.0, 'recall': 0.6371054, 'accuracy_baseline': 0.7638323, 'accuracy': 0.8503011, 'prediction/mean': 0.23193118, 'global_step': 6513, 'label/mean': 0.23616774, 'precision': 0.7015977, 'auc': 0.89935285}\n",
      "##########################################\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = TRAIN_DATA_SIZE\n",
    "TEST_SIZE = TEST_DATA_SIZE\n",
    "\n",
    "train_input_fn = lambda:csv_input_fn(file_names = TRAIN_DATA_FILES_PATTERN,\n",
    "                                    mode = tf.estimator.ModeKeys.EVAL,\n",
    "                                    batch_size = TRAIN_SIZE)\n",
    "test_input_fn = lambda: csv_input_fn(file_names = TEST_DATA_FILES_PATTERN,\n",
    "                                    mode = tf.estimator.ModeKeys.EVAL,\n",
    "                                    batch_size = TEST_SIZE)\n",
    "\n",
    "estimator = create_DNNComb_estimator(run_config,hparams)\n",
    "\n",
    "train_results = estimator.evaluate(input_fn = train_input_fn,steps=1)\n",
    "print(\"\\n\")\n",
    "print(\"#################################\")\n",
    "print('#训练结果指标：{}'.format(train_results))\n",
    "print('######################################')\n",
    "\n",
    "test_results = estimator.evaluate(input_fn=test_input_fn,steps=1)\n",
    "print('')\n",
    "print(\"####################################\")\n",
    "\n",
    "test_results = estimator.evaluate(input_fn = test_input_fn,steps =1)\n",
    "print('')\n",
    "print('##########################################')\n",
    "print('#测试结果指标：{}'.format(test_results))\n",
    "print('##########################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10、预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "数据输入函数input_fn:\n",
      "====================\n",
      "输入文件：adult_test.csv\n",
      "一批大小：10\n",
      "迭代的轮次：None\n",
      "模式：infer\n",
      "Thread Count:4\n",
      "Shuffle:False\n",
      "===================\n",
      "/n <ParallelMapDataset shapes: ({relationship: (?,), gender: (?,), marital_status: (?,), native_country: (?,), education_num: (?,), education: (?,), fnlwgt: (?,), workclass: (?,), capital_loss: (?,), occupation: (?,), hours_per_week: (?,), capital_gain: (?,), race: (?,), age: (?,)}, (?,)), types: ({relationship: tf.string, gender: tf.string, marital_status: tf.string, native_country: tf.string, education_num: tf.int32, education: tf.string, fnlwgt: tf.int32, workclass: tf.string, capital_loss: tf.int32, occupation: tf.string, hours_per_week: tf.int32, capital_gain: tf.int32, race: tf.string, age: tf.int32}, tf.string)>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from D&W Model/model.ckpt-6513\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "预测的类别：[0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
      "预测概率为：[[0.9999981, 1.8477958e-06], [0.84116644, 0.1588336], [0.8458963, 0.15410371], [0.16203985, 0.8379602], [0.9999999, 6.497228e-08], [0.999982, 1.8003888e-05], [0.99999166, 8.389283e-06], [0.44208094, 0.557919], [0.9986999, 0.0013000364], [0.9999602, 3.9755338e-05]]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "# 输入\n",
    "predict_input_fn = lambda:csv_input_fn(TEST_DATA_FILES_PATTERN,\n",
    "                                      mode = tf.estimator.ModeKeys.PREDICT,\n",
    "                                      batch_size = 10)\n",
    "predictions = list(itertools.islice(estimator.predict(input_fn = predict_input_fn),10))\n",
    "print('')\n",
    "print('预测的类别：{}'.format(list(map(lambda item: item['class_ids'][0],predictions))))\n",
    "print('预测概率为：{}'.format(list(map(lambda item: list(item['probabilities']),predictions))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
